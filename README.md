# Q-Learning applied to OpenAI's cart-pole problem

This is my implementation of Q-learning on OpenAI's cart pole problem. Despite the state space being continuous for this problem, I discretize the values into buckets allowing Q-learning to function. 

The model fairly consistently solves the environment in about 600 episodes.

## Example

The learned model balancing the pole.

![Cart](docs/learned.gif)

## Runs

<img src="docs/Figure_1.png" width="400" />
<img src="docs/Figure_2.png" width="400" />
<img src="docs/Figure_3.png" width="400" />

